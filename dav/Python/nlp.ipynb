{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cam-5lkI3cjS"
      },
      "source": [
        "## Stopwords and Punctuation Removal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6QufU_01KMi",
        "outputId": "9d8d54b1-39eb-44c6-d10b-1bf91c1e1a73"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\Raunak\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Raunak\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import string\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ge56MIHx1kli"
      },
      "outputs": [],
      "source": [
        "stopwords_eng = set(stopwords.words('english'))\n",
        "txt = \"What to do now ,it is free time\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBjvFcyY1ySh",
        "outputId": "974ea39a-8326-4004-cf7c-8f0f2d45a9cc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['What', 'to', 'do', 'now', 'it', 'is', 'free', 'time']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = word_tokenize(txt)\n",
        "tokens = [token for token in tokens if token not in string.punctuation]\n",
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xDEBMRH113VB",
        "outputId": "51a0ea52-999e-48b5-be2e-1e65e52f03e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'What free time'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_txt = \" \".join([token for token in tokens if token not in stopwords_eng])\n",
        "filtered_txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-aIABkX3laB"
      },
      "source": [
        "## Stemmetization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4yU1FuT3nkh",
        "outputId": "67715790-7722-41a6-99fe-2cf64f500102"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Raunak\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\Raunak\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "sb4-NaLs3xIx"
      },
      "outputs": [],
      "source": [
        "txt = \"Running runners run quickly towards the finishing line.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YSSfNqhy30_x"
      },
      "outputs": [],
      "source": [
        "def stem_txt(text: str):\n",
        "    tokens = text.lower().split()\n",
        "    return \" \".join([stemmer.stem(token) for token in tokens])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_E4et0dc4ALB",
        "outputId": "b51d3875-ec07-4d2a-8ff5-4bf7386e03a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'run runner run quickli toward the finish line.'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "stem_txt(txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg4bIj6K4zER"
      },
      "source": [
        "## Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phCyMKGC5Oop",
        "outputId": "5fac4581-b7bf-4a87-c8c6-dfcec2f0d2b9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Raunak\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\Raunak\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\Raunak\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\Raunak\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cKPX2yfq5UMh"
      },
      "outputs": [],
      "source": [
        "lemm = WordNetLemmatizer()\n",
        "txt = \"The leaves are falling from the trees, and the children are running happily.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "E3-xoG2W5afh",
        "outputId": "ab099f3f-57b1-43ee-8d19-804d9972e86b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'The leaf are falling from the tree , and the child are running happily .'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def lemm_txt(text: str):\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    return \" \".join([lemm.lemmatize(token) for token in tokens])\n",
        "\n",
        "lemm_txt(txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2smvsXI5_nh"
      },
      "source": [
        "## Bag of Words (BoW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iSd9xGWR6J2i"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DBv5dLOY5-zC"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"Hello world! This is a sample text.\",\n",
        "    \"Bag of words model is simple.\",\n",
        "    \"This is another example of text processing.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05bX65_K6RGR",
        "outputId": "55057aec-8672-4d73-eed0-6af7a39feb25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary: ['another' 'bag' 'example' 'hello' 'is' 'model' 'of' 'processing' 'sample'\n",
            " 'simple' 'text' 'this' 'words' 'world']\n"
          ]
        }
      ],
      "source": [
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(f\"Vocabulary: {vectorizer.get_feature_names_out()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bblSGSreGxli",
        "outputId": "1d72c4e2-a06d-4986-c5fe-fbd4d7011396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 1 1 0 0 0 1 0 1 1 0 1]\n",
            " [0 1 0 0 1 1 1 0 0 1 0 0 1 0]\n",
            " [1 0 1 0 1 0 1 1 0 0 1 1 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6htMO4b6a-h",
        "outputId": "78d1aa8b-a58b-4032-938b-16222db6f324"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 19 stored elements and shape (3, 14)>\n",
            "  Coords\tValues\n",
            "  (0, 3)\t1\n",
            "  (0, 13)\t1\n",
            "  (0, 11)\t1\n",
            "  (0, 4)\t1\n",
            "  (0, 8)\t1\n",
            "  (0, 10)\t1\n",
            "  (1, 4)\t1\n",
            "  (1, 1)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 12)\t1\n",
            "  (1, 5)\t1\n",
            "  (1, 9)\t1\n",
            "  (2, 11)\t1\n",
            "  (2, 4)\t1\n",
            "  (2, 10)\t1\n",
            "  (2, 6)\t1\n",
            "  (2, 0)\t1\n",
            "  (2, 2)\t1\n",
            "  (2, 7)\t1\n"
          ]
        }
      ],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptyB010I7-jK"
      },
      "source": [
        "## TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "g6Lr63m58SsK"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "H2urbuEU8Mlh"
      },
      "outputs": [],
      "source": [
        "corpus = [\n",
        "    \"This is a sample document.\",\n",
        "    \"This document is another example.\",\n",
        "    \"We are learning TF-IDF in NLP.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nduP8hAY8ZCh",
        "outputId": "be4a6270-27e1-47c4-eaae-075f3a1d13ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.         0.         0.45985353 0.         0.         0.\n",
            "  0.45985353 0.         0.         0.60465213 0.         0.45985353\n",
            "  0.        ]\n",
            " [0.51741994 0.         0.3935112  0.51741994 0.         0.\n",
            "  0.3935112  0.         0.         0.         0.         0.3935112\n",
            "  0.        ]\n",
            " [0.         0.37796447 0.         0.         0.37796447 0.37796447\n",
            "  0.         0.37796447 0.37796447 0.         0.37796447 0.\n",
            "  0.37796447]]\n"
          ]
        }
      ],
      "source": [
        "X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d94zooPd8fph",
        "outputId": "826a3793-8513-44ca-e256-43decc24038d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 16 stored elements and shape (3, 13)>\n",
            "  Coords\tValues\n",
            "  (0, 11)\t0.4598535287588349\n",
            "  (0, 6)\t0.4598535287588349\n",
            "  (0, 9)\t0.6046521283053111\n",
            "  (0, 2)\t0.4598535287588349\n",
            "  (1, 11)\t0.39351120409397233\n",
            "  (1, 6)\t0.39351120409397233\n",
            "  (1, 2)\t0.39351120409397233\n",
            "  (1, 0)\t0.5174199439321682\n",
            "  (1, 3)\t0.5174199439321682\n",
            "  (2, 12)\t0.37796447300922725\n",
            "  (2, 1)\t0.37796447300922725\n",
            "  (2, 7)\t0.37796447300922725\n",
            "  (2, 10)\t0.37796447300922725\n",
            "  (2, 4)\t0.37796447300922725\n",
            "  (2, 5)\t0.37796447300922725\n",
            "  (2, 8)\t0.37796447300922725\n"
          ]
        }
      ],
      "source": [
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neHgrytN8hYy",
        "outputId": "c1b9066b-bcd2-49f0-e732-936d72f3b3e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['another', 'are', 'document', 'example', 'idf', 'in', 'is',\n",
              "       'learning', 'nlp', 'sample', 'tf', 'this', 'we'], dtype=object)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorizer.get_feature_names_out()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rni7GSyp8tDR"
      },
      "source": [
        "## Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYSFOXQP85Yh",
        "outputId": "89879a0e-050c-4fa8-a030-f41a9222fb1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     C:\\Users\\Raunak\\AppData\\Roaming\\nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "nltk.download('vader_lexicon')\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "IDPKNgC88yTA"
      },
      "outputs": [],
      "source": [
        "sentences = [\n",
        "    \"I absolutely love this product! It's amazing. 😊\",\n",
        "    \"This is the worst experience I've ever had. Terrible service!\",\n",
        "    \"The movie was okay, not great but not bad either.\",\n",
        "    \"I'm not sure how I feel about this.\",\n",
        "    \"What a fantastic experience! I'll definitely come back.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UuQfzMm8-8x",
        "outputId": "4cc2b471-d8a2-428e-e4c9-a9dd3f07812b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.0, 'neu': 0.318, 'pos': 0.682, 'compound': 0.862}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sia.polarity_scores(sentences[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk32KMpM9G8h",
        "outputId": "30b426c9-befc-44a9-e67b-bebde0052924"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I absolutely love this product! It's amazing. 😊 | Score: 0.862\n",
            "Category: Positive\n",
            "\n",
            "This is the worst experience I've ever had. Terrible service! | Score: -0.8172\n",
            "Category: Negative\n",
            "\n",
            "The movie was okay, not great but not bad either. | Score: 0.4728\n",
            "Category: Positive\n",
            "\n",
            "I'm not sure how I feel about this. | Score: -0.2411\n",
            "Category: Negative\n",
            "\n",
            "What a fantastic experience! I'll definitely come back. | Score: 0.7644\n",
            "Category: Positive\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "    score = sia.polarity_scores(sentence)\n",
        "    print(f\"{sentence} | Score: {score['compound']}\")\n",
        "\n",
        "    category = \"Positive\" if score['compound'] >= 0.05 else \"Negative\" if score['compound'] <= -0.05 else \"Neutral\"\n",
        "    print(f\"Category: {category}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVeoMzzW99jx"
      },
      "source": [
        "## Sentiment Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHng6YP2901R",
        "outputId": "fb8aca98-2499-4020-c1d7-076daae67f92"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\Raunak\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\Raunak\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "xZT05w9G-nOR"
      },
      "outputs": [],
      "source": [
        "data = {\n",
        "    \"text\": [\n",
        "        \"I love this product! It's amazing.\",\n",
        "        \"This is the worst experience ever.\",\n",
        "        \"The food was okay, nothing special.\",\n",
        "        \"I am extremely happy with the service!\",\n",
        "        \"I hate this, it’s terrible.\",\n",
        "        \"It was an average experience.\"\n",
        "    ],\n",
        "    \"sentiment\": [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"neutral\"]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "iDxqC4RQ-1Eg",
        "outputId": "3548cdbf-c8eb-4bfe-8c3d-8f9d8bc62260"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love this product! It's amazing.</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is the worst experience ever.</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The food was okay, nothing special.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I am extremely happy with the service!</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I hate this, it’s terrible.</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>It was an average experience.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     text sentiment\n",
              "0      I love this product! It's amazing.  positive\n",
              "1      This is the worst experience ever.  negative\n",
              "2     The food was okay, nothing special.   neutral\n",
              "3  I am extremely happy with the service!  positive\n",
              "4             I hate this, it’s terrible.  negative\n",
              "5           It was an average experience.   neutral"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "id": "-fbZYUUi-4Kw",
        "outputId": "53e578c4-3fda-446a-ddfe-aadcbbf44656"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>processed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love this product! It's amazing.</td>\n",
              "      <td>positive</td>\n",
              "      <td>I love product Its amazing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This is the worst experience ever.</td>\n",
              "      <td>negative</td>\n",
              "      <td>This worst experience ever</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The food was okay, nothing special.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>The food okay nothing special</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I am extremely happy with the service!</td>\n",
              "      <td>positive</td>\n",
              "      <td>I extremely happy service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I hate this, it’s terrible.</td>\n",
              "      <td>negative</td>\n",
              "      <td>I hate terrible</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>It was an average experience.</td>\n",
              "      <td>neutral</td>\n",
              "      <td>It average experience</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     text sentiment  \\\n",
              "0      I love this product! It's amazing.  positive   \n",
              "1      This is the worst experience ever.  negative   \n",
              "2     The food was okay, nothing special.   neutral   \n",
              "3  I am extremely happy with the service!  positive   \n",
              "4             I hate this, it’s terrible.  negative   \n",
              "5           It was an average experience.   neutral   \n",
              "\n",
              "                  processed_text  \n",
              "0     I love product Its amazing  \n",
              "1     This worst experience ever  \n",
              "2  The food okay nothing special  \n",
              "3      I extremely happy service  \n",
              "4                I hate terrible  \n",
              "5          It average experience  "
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def preprocess_text(text: str):\n",
        "    txt = text.lower()\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    words = word_tokenize(text)\n",
        "    words = [word for word in words if word not in stopwords.words('english')]\n",
        "    return ' '.join(words)\n",
        "\n",
        "df['processed_text'] = df['text'].apply(preprocess_text)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "KrV5-sob_RRx"
      },
      "outputs": [],
      "source": [
        "le = LabelEncoder()\n",
        "tfid = TfidfVectorizer()\n",
        "\n",
        "X = tfid.fit_transform(df['processed_text'])\n",
        "y = le.fit_transform(df['sentiment'])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQ20GzIBFcIS",
        "outputId": "715ed999-381b-4bf0-aea5-3672d1559158"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([2, 0]), array([2, 0]))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = MultinomialNB().fit(X, y)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "y_test, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_-sNtyAQG6ip"
      },
      "outputs": [],
      "source": [
        "def train(data: pd.DataFrame, split: Optional[float]=None):\n",
        "    \"\"\"\n",
        "    Train a NB Model using Tf-IDF Vectorizer and Label Encoder.\n",
        "\n",
        "    Returns:\n",
        "    - model: Trained model\n",
        "    - tfid: Tf-IDF Vectorizer\n",
        "    - le: Label Encoder\n",
        "    \"\"\"\n",
        "    le = LabelEncoder()\n",
        "    tfid = TfidfVectorizer()\n",
        "    model = MultinomialNB()\n",
        "\n",
        "    X = tfid.fit_transform(data['processed_text'])\n",
        "    y = le.fit_transform(data['sentiment'])\n",
        "\n",
        "    if split:\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=split, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        return model, tfid, le\n",
        "\n",
        "    model.fit(X, y)\n",
        "\n",
        "    return model, tfid, le\n",
        "\n",
        "\n",
        "def predict(text, model, tfid, le):\n",
        "    preds = model.predict(tfid.transform(text))\n",
        "    return le.inverse_transform(preds)\n",
        "\n",
        "def metrics(X_test, y_test, model, tfid, le):\n",
        "    y_pred = predict(X_test, model, tfid, le)\n",
        "    y_pred = le.transform(y_pred)\n",
        "    y_test = le.transform(y_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, zero_division=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "B8iF8jWqH4Py"
      },
      "outputs": [],
      "source": [
        "model, tfid, le = train(df)\n",
        "model1, tfid1, le1 = train(df, split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGzcXcKpINUR",
        "outputId": "e1c648bb-de68-48d0-ad4a-af8764b5aa1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['positive' 'negative' 'neutral' 'positive' 'negative' 'neutral']\n",
            "['neutral' 'neutral' 'neutral' 'positive' 'negative' 'neutral']\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         6\n",
            "   macro avg       1.00      1.00      1.00         6\n",
            "weighted avg       1.00      1.00      1.00         6\n",
            "\n",
            "Accuracy: 0.6666666666666666\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.50      1.00      0.67         2\n",
            "           2       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.67         6\n",
            "   macro avg       0.83      0.67      0.67         6\n",
            "weighted avg       0.83      0.67      0.67         6\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(predict(df['processed_text'], model, tfid, le))\n",
        "print(predict(df['processed_text'], model1, tfid1, le1))\n",
        "\n",
        "metrics(df['processed_text'], df['sentiment'], model, tfid, le)\n",
        "metrics(df['processed_text'], df['sentiment'], model1, tfid1, le1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGK4gwj6CxFZ"
      },
      "source": [
        "## Spacy Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cwIylLaBgdB"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "# run in terminal : python -m spacy download en_core_web_sm\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oyeF9bJCs7w"
      },
      "outputs": [],
      "source": [
        "def get_pos_lemm(text: str):\n",
        "    doc = nlp(text)\n",
        "    pos = [(token.text, token.lemma_, token.pos_) for token in doc]\n",
        "    # pos = [(f\"Original: {token.text}, Lemma: {token.lemma_}, POS: {token.pos_}\") for token in doc]\n",
        "    lemm_txt = \" \".join([token.lemma_ for token in doc])\n",
        "\n",
        "    return pos, lemm_txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLsi8R4-DZQR",
        "outputId": "f9ec911c-9757-4b91-aa8c-0825b918dbfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "POS: [('Running', 'run', 'VERB'), ('is', 'be', 'AUX'), ('my', 'my', 'PRON'), ('great', 'great', 'ADJ'), ('habit', 'habit', 'NOUN')]\n",
            "Lemmatized text: run be my great habit\n"
          ]
        }
      ],
      "source": [
        "txt = \"Running is my great habit\"\n",
        "\n",
        "pos, lemm_txt = get_pos_lemm(txt)\n",
        "\n",
        "print(f\"POS: {pos}\")\n",
        "print(f\"Lemmatized text: {lemm_txt}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Cam-5lkI3cjS",
        "D-aIABkX3laB",
        "zg4bIj6K4zER",
        "M2smvsXI5_nh",
        "ptyB010I7-jK",
        "rni7GSyp8tDR"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
